{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_network():\n",
    "     # Loading COCO class labels from file\n",
    "    # Opening file\n",
    "    # Pay attention! If you're using Windows, yours path might looks like:\n",
    "    # r'yolo-coco-data\\coco.names'\n",
    "    # or:\n",
    "    # 'yolo-coco-data\\\\coco.names'\n",
    "    with open(\"C:\\BioVision_ds\\Saliency\\classes.names\") as f:\n",
    "        # Getting labels reading every line\n",
    "        # and putting them into the list\n",
    "        labels = [line.strip() for line in f]\n",
    "\n",
    "    # Loading trained YOLO v3 Objects Detector\n",
    "    # with the help of 'dnn' library from OpenCV\n",
    "    # Pay attention! If you're using Windows, yours paths might look like:\n",
    "    # r'yolo-coco-data\\yolov3.cfg'\n",
    "    # r'yolo-coco-data\\yolov3.weights'\n",
    "    # or:\n",
    "    # 'yolo-coco-data\\\\yolov3.cfg'\n",
    "    # 'yolo-coco-data\\\\yolov3.weights'\n",
    "    network = cv2.dnn.readNetFromDarknet(\"C:\\\\Users\\\\shush\\\\darknet\\\\build\\\\darknet\\\\x64\\\\cfg\\\\yolov3bv.cfg\",\n",
    "                                         \"C:\\\\Users\\\\shush\\\\darknet\\\\build\\\\darknet\\\\x64\\\\backup\\\\yolov3_last.weights\")\n",
    "\n",
    "    # Getting list with names of all layers from YOLO v3 network\n",
    "    layers_names_all = network.getLayerNames()\n",
    "\n",
    "    # Check point\n",
    "    # print()\n",
    "    # print(layers_names_all)\n",
    "\n",
    "    # Getting only output layers' names that we need from YOLO v3 algorithm\n",
    "    # with function that returns indexes of layers with unconnected outputs\n",
    "    layers_names_output = \\\n",
    "        [layers_names_all[i[0] - 1] for i in network.getUnconnectedOutLayers()]\n",
    "\n",
    "    # Check point\n",
    "    # print()\n",
    "    # print(layers_names_output)  # ['yolo_82', 'yolo_94', 'yolo_106']\n",
    "\n",
    "    \n",
    "    return network, layers_names_output, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo3(path, path2, network, layers_names_output, labels):\n",
    "    # Setting minimum probability to eliminate weak predictions\n",
    "    probability_minimum = 0.5\n",
    "\n",
    "    # Setting threshold for filtering weak bounding boxes\n",
    "    # with non-maximum suppression\n",
    "    threshold = 0.3\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Start of:\n",
    "    Reading input image\n",
    "    \"\"\"\n",
    "\n",
    "    # Reading image with OpenCV library\n",
    "    # In this way image is opened already as numpy array\n",
    "    # WARNING! OpenCV by default reads images in BGR format\n",
    "    image_BGR = path\n",
    "    image_BGR2 = path2\n",
    "\n",
    "    # Check point\n",
    "    # Showing image shape\n",
    "    print()\n",
    "    print('Image shape:', image_BGR.shape)  # tuple of (466, 700, 3)\n",
    "\n",
    "    # Getting spatial dimension of input image\n",
    "    h, w = image_BGR.shape[:2]  # Slicing from tuple only first two elements\n",
    "\n",
    "    # Check point\n",
    "    # Showing height an width of image\n",
    "    print('Image height={0} and width={1}'.format(h, w))  # 466 700\n",
    "\n",
    "    \"\"\"\n",
    "    End of: \n",
    "    Reading input image\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Start of:\n",
    "    Getting blob from input image\n",
    "    \"\"\"\n",
    "\n",
    "    # Getting blob from input image\n",
    "    # The 'cv2.dnn.blobFromImage' function returns 4-dimensional blob\n",
    "    # from input image after mean subtraction, normalizing, and RB channels swapping\n",
    "    # Resulted shape has number of images, number of channels, width and height\n",
    "    # E.G.:\n",
    "    # blob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size, mean, swapRB=True)\n",
    "    blob = cv2.dnn.blobFromImage(image_BGR, 1 / 255.0, (416, 416),\n",
    "                                 swapRB=True, crop=False)\n",
    "\n",
    "    # Check point\n",
    "    print('Blob shape:', blob.shape)  # (1, 3, 416, 416)\n",
    "\n",
    "    \"\"\"\n",
    "    End of:\n",
    "    Getting blob from input image\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Start of:\n",
    "    Loading YOLO v3 network\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Generating colours for representing every detected object\n",
    "    # with function randint(low, high=None, size=None, dtype='l')\n",
    "    colours = np.random.randint(0, 255, size=(1, 3), dtype='uint8')\n",
    "\n",
    "    # Check point\n",
    "    # print()\n",
    "    # print(type(colours))  # <class 'numpy.ndarray'>\n",
    "    # print(colours.shape)  # (80, 3)\n",
    "    # print(colours[0])  # [172  10 127]\n",
    "\n",
    "    \"\"\"\n",
    "    End of:\n",
    "    Loading YOLO v3 network\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Start of:\n",
    "    Implementing Forward pass\n",
    "    \"\"\"\n",
    "\n",
    "    # Implementing forward pass with our blob and only through output layers\n",
    "    # Calculating at the same time, needed time for forward pass\n",
    "    network.setInput(blob)  # setting blob as input to the network\n",
    "    start = time.time()\n",
    "    output_from_network = network.forward(layers_names_output)\n",
    "    end = time.time()\n",
    "\n",
    "    # Showing spent time for forward pass\n",
    "    print()\n",
    "    print('Objects Detection took {:.5f} seconds'.format(end - start))\n",
    "\n",
    "    \"\"\"\n",
    "    End of:\n",
    "    Implementing Forward pass\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Start of:\n",
    "    Getting bounding boxes\n",
    "    \"\"\"\n",
    "\n",
    "    # Preparing lists for detected bounding boxes,\n",
    "    # obtained confidences and class's number\n",
    "    bounding_boxes = []\n",
    "    confidences = []\n",
    "    class_numbers = []\n",
    "\n",
    "    # Going through all output layers after feed forward pass\n",
    "    for result in output_from_network:\n",
    "        # Going through all detections from current output layer\n",
    "        for detected_objects in result:\n",
    "            # Getting 80 classes' probabilities for current detected object\n",
    "            scores = detected_objects[5:]\n",
    "            # Getting index of the class with the maximum value of probability\n",
    "            class_current = np.argmax(scores)\n",
    "            # Getting value of probability for defined class\n",
    "            confidence_current = scores[class_current]\n",
    "\n",
    "            # # Check point\n",
    "            # # Every 'detected_objects' numpy array has first 4 numbers with\n",
    "            # # bounding box coordinates and rest 80 with probabilities for every class\n",
    "            # print(detected_objects.shape)  # (85,)\n",
    "\n",
    "            # Eliminating weak predictions with minimum probability\n",
    "            if confidence_current > probability_minimum:\n",
    "                # Scaling bounding box coordinates to the initial image size\n",
    "                # YOLO data format keeps coordinates for center of bounding box\n",
    "                # and its current width and height\n",
    "                # That is why we can just multiply them elementwise\n",
    "                # to the width and height\n",
    "                # of the original image and in this way get coordinates for center\n",
    "                # of bounding box, its width and height for original image\n",
    "                box_current = detected_objects[0:4] * np.array([w, h, w, h])\n",
    "\n",
    "                # Now, from YOLO data format, we can get top left corner coordinates\n",
    "                # that are x_min and y_min\n",
    "                x_center, y_center, box_width, box_height = box_current\n",
    "                x_min = int(x_center - (box_width / 2))\n",
    "                y_min = int(y_center - (box_height / 2))\n",
    "\n",
    "                # Adding results into prepared lists\n",
    "                bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n",
    "                print(bounding_boxes)\n",
    "                confidences.append(float(confidence_current))\n",
    "                class_numbers.append(class_current)\n",
    "\n",
    "    \"\"\"\n",
    "    End of:\n",
    "    Getting bounding boxes\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Start of:\n",
    "    Non-maximum suppression\n",
    "    \"\"\"\n",
    "\n",
    "    # Implementing non-maximum suppression of given bounding boxes\n",
    "    # With this technique we exclude some of bounding boxes if their\n",
    "    # corresponding confidences are low or there is another\n",
    "    # bounding box for this region with higher confidence\n",
    "\n",
    "    # It is needed to make sure that data type of the boxes is 'int'\n",
    "    # and data type of the confidences is 'float'\n",
    "    # https://github.com/opencv/opencv/issues/12789\n",
    "    results = cv2.dnn.NMSBoxes(bounding_boxes, confidences,\n",
    "                               probability_minimum, threshold)\n",
    "\n",
    "    \"\"\"\n",
    "    End of:\n",
    "    Non-maximum suppression\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Start of:\n",
    "    Drawing bounding boxes and labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Defining counter for detected objects\n",
    "    counter = 1\n",
    "\n",
    "    # Checking if there is at least one detected object after non-maximum suppression\n",
    "    if len(results) > 0:\n",
    "        # Going through indexes of results\n",
    "        for i in results.flatten():\n",
    "            # Showing labels of the detected objects\n",
    "            print('Object {0}: {1}'.format(counter, labels[int(class_numbers[i])]))\n",
    "\n",
    "            # Incrementing counter\n",
    "            counter += 1\n",
    "\n",
    "            # Getting current bounding box coordinates,\n",
    "            # its width and height\n",
    "            x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
    "            box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
    "\n",
    "            # Preparing colour for current bounding box\n",
    "            # and converting from numpy array to list\n",
    "            colour_box_current = colours[class_numbers[i]].tolist()\n",
    "\n",
    "            # # # Check point\n",
    "            # print(type(colour_box_current))  # <class 'list'>\n",
    "            # print(colour_box_current)  # [172 , 10, 127]\n",
    "\n",
    "            # Drawing bounding box on the original image\n",
    "            cv2.rectangle(image_BGR2, (x_min, y_min),\n",
    "                          (x_min + box_width, y_min + box_height),\n",
    "                          colour_box_current, 2)\n",
    "\n",
    "            # Preparing text with label and confidence for current bounding box\n",
    "            text_box_current = '{}: {:.4f}'.format(labels[int(class_numbers[i])],\n",
    "                                                   confidences[i]) + str(bounding_boxes)\n",
    "\n",
    "            # Putting text with label and confidence on the original image\n",
    "            cv2.putText(image_BGR2, text_box_current, (x_min, y_min - 5),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX, 0.7, colour_box_current, 2)\n",
    "\n",
    "    # Comparing how many objects where before non-maximum suppression\n",
    "    # and left after\n",
    "    print()\n",
    "    print('Total objects been detected:', len(bounding_boxes))\n",
    "    print('Number of objects left after non-maximum suppression:', counter - 1)\n",
    "\n",
    "    \"\"\"\n",
    "    End of:\n",
    "    Drawing bounding boxes and labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Saving resulted image in jpg format by OpenCV function\n",
    "    # that uses extension to choose format to save with\n",
    "    return image_BGR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 1.02526 seconds\n",
      "[[255, 59, 166, 93]]\n",
      "[[255, 59, 166, 93], [85, 81, 169, 156]]\n",
      "[[255, 59, 166, 93], [85, 81, 169, 156], [91, 86, 153, 165]]\n",
      "[[255, 59, 166, 93], [85, 81, 169, 156], [91, 86, 153, 165], [218, 282, 214, 81]]\n",
      "[[255, 59, 166, 93], [85, 81, 169, 156], [91, 86, 153, 165], [218, 282, 214, 81], [234, 283, 203, 71]]\n",
      "Object 1: object\n",
      "Object 2: object\n",
      "Object 3: object\n",
      "\n",
      "Total objects been detected: 5\n",
      "Number of objects left after non-maximum suppression: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network, a1, a2 = set_up_network()\n",
    "image = cv2.imread(\"C:\\\\BioVision_ds\\\\Saliency\\\\mRNA57.jpg\")\n",
    "yolo = yolo3(image,image, network, a1, a2)\n",
    "\n",
    "cv2.imwrite(\"yolo1.jpg\", yolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(\"C:\\\\BioVision_ds\\\\Original\\\\mRNA57.jpg\")\n",
    "[x_min, y_min, box_width, box_height] = [91, 86, 153, 165]\n",
    "cv2.rectangle(image, (x_min, y_min),\n",
    "                          (x_min + box_width, y_min + box_height),\n",
    "                          (0,0,255), 4)\n",
    "cv2.imwrite(\"final1.jpg\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 2.27781 seconds\n",
      "\n",
      "Total objects been detected: 0\n",
      "Number of objects left after non-maximum suppression: 0\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 1.01728 seconds\n",
      "[[98, 27, 287, 265]]\n",
      "[[98, 27, 287, 265], [107, 40, 271, 268]]\n",
      "Object 1: object\n",
      "\n",
      "Total objects been detected: 2\n",
      "Number of objects left after non-maximum suppression: 1\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 1.05418 seconds\n",
      "\n",
      "Total objects been detected: 0\n",
      "Number of objects left after non-maximum suppression: 0\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 0.85271 seconds\n",
      "\n",
      "Total objects been detected: 0\n",
      "Number of objects left after non-maximum suppression: 0\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 0.82978 seconds\n",
      "\n",
      "Total objects been detected: 0\n",
      "Number of objects left after non-maximum suppression: 0\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 0.87765 seconds\n",
      "\n",
      "Total objects been detected: 0\n",
      "Number of objects left after non-maximum suppression: 0\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 1.05418 seconds\n",
      "[[106, 15, 267, 269]]\n",
      "[[106, 15, 267, 269], [97, 22, 292, 264]]\n",
      "[[106, 15, 267, 269], [97, 22, 292, 264], [184, 204, 67, 47]]\n",
      "Object 1: object\n",
      "Object 2: object\n",
      "\n",
      "Total objects been detected: 3\n",
      "Number of objects left after non-maximum suppression: 2\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 0.94049 seconds\n",
      "\n",
      "Total objects been detected: 0\n",
      "Number of objects left after non-maximum suppression: 0\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 0.89361 seconds\n",
      "\n",
      "Total objects been detected: 0\n",
      "Number of objects left after non-maximum suppression: 0\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 0.81980 seconds\n",
      "\n",
      "Total objects been detected: 0\n",
      "Number of objects left after non-maximum suppression: 0\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 0.88264 seconds\n",
      "[[47, 129, 161, 208]]\n",
      "[[47, 129, 161, 208], [300, 220, 168, 138]]\n",
      "Object 1: object\n",
      "Object 2: object\n",
      "\n",
      "Total objects been detected: 2\n",
      "Number of objects left after non-maximum suppression: 2\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 0.86170 seconds\n",
      "[[127, 60, 235, 244]]\n",
      "[[127, 60, 235, 244], [121, 58, 244, 247]]\n",
      "Object 1: object\n",
      "\n",
      "Total objects been detected: 2\n",
      "Number of objects left after non-maximum suppression: 1\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 1.00032 seconds\n",
      "\n",
      "Total objects been detected: 0\n",
      "Number of objects left after non-maximum suppression: 0\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 1.33941 seconds\n",
      "\n",
      "Total objects been detected: 0\n",
      "Number of objects left after non-maximum suppression: 0\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 0.92652 seconds\n",
      "\n",
      "Total objects been detected: 0\n",
      "Number of objects left after non-maximum suppression: 0\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 1.05019 seconds\n",
      "\n",
      "Total objects been detected: 0\n",
      "Number of objects left after non-maximum suppression: 0\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 1.05917 seconds\n",
      "\n",
      "Total objects been detected: 0\n",
      "Number of objects left after non-maximum suppression: 0\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 1.19232 seconds\n",
      "\n",
      "Total objects been detected: 0\n",
      "Number of objects left after non-maximum suppression: 0\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 1.01229 seconds\n",
      "\n",
      "Total objects been detected: 0\n",
      "Number of objects left after non-maximum suppression: 0\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 1.56980 seconds\n",
      "\n",
      "Total objects been detected: 0\n",
      "Number of objects left after non-maximum suppression: 0\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 1.30004 seconds\n",
      "[[198, 98, 95, 209]]\n",
      "Object 1: object\n",
      "\n",
      "Total objects been detected: 1\n",
      "Number of objects left after non-maximum suppression: 1\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 1.50198 seconds\n",
      "\n",
      "Total objects been detected: 0\n",
      "Number of objects left after non-maximum suppression: 0\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 1.26064 seconds\n",
      "[[148, 79, 198, 170]]\n",
      "[[148, 79, 198, 170], [138, 92, 215, 156]]\n",
      "[[148, 79, 198, 170], [138, 92, 215, 156], [163, 221, 160, 91]]\n",
      "Object 1: object\n",
      "Object 2: object\n",
      "\n",
      "Total objects been detected: 3\n",
      "Number of objects left after non-maximum suppression: 2\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 1.40524 seconds\n",
      "[[124, 90, 252, 194]]\n",
      "[[124, 90, 252, 194], [128, 92, 263, 189]]\n",
      "[[124, 90, 252, 194], [128, 92, 263, 189], [122, 103, 259, 183]]\n",
      "Object 1: object\n",
      "\n",
      "Total objects been detected: 3\n",
      "Number of objects left after non-maximum suppression: 1\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 1.28357 seconds\n",
      "[[164, 84, 171, 247]]\n",
      "[[164, 84, 171, 247], [183, 89, 158, 233]]\n",
      "Object 1: object\n",
      "\n",
      "Total objects been detected: 2\n",
      "Number of objects left after non-maximum suppression: 1\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 1.22672 seconds\n",
      "[[109, 82, 192, 247]]\n",
      "Object 1: object\n",
      "\n",
      "Total objects been detected: 1\n",
      "Number of objects left after non-maximum suppression: 1\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 1.09607 seconds\n",
      "[[160, 92, 172, 233]]\n",
      "Object 1: object\n",
      "\n",
      "Total objects been detected: 1\n",
      "Number of objects left after non-maximum suppression: 1\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 0.87964 seconds\n",
      "[[152, 87, 191, 207]]\n",
      "[[152, 87, 191, 207], [140, 105, 219, 194]]\n",
      "Object 1: object\n",
      "\n",
      "Total objects been detected: 2\n",
      "Number of objects left after non-maximum suppression: 1\n",
      "\n",
      "Image shape: (360, 480, 3)\n",
      "Image height=360 and width=480\n",
      "Blob shape: (1, 3, 416, 416)\n",
      "\n",
      "Objects Detection took 0.83077 seconds\n",
      "[[123, 115, 242, 180]]\n",
      "Object 1: object\n",
      "\n",
      "Total objects been detected: 1\n",
      "Number of objects left after non-maximum suppression: 1\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "vid = cv2.VideoCapture(r\"C:\\Users\\shush\\OneDrive\\Documents\\Projects\\OpenCVtut\\videoplayback.mp4\")\n",
    "frame_width = int(vid.get(3))\n",
    "frame_height = int(vid.get(4))  \n",
    "size = (frame_width, frame_height)\n",
    "saliency = None\n",
    "obj_dect = cv2.createBackgroundSubtractorKNN()\n",
    "result_vid = cv2.VideoWriter('result.avi', \n",
    "                         cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "                         10, size)\n",
    "network, a1, a2 = set_up_network()\n",
    "count = 0\n",
    "while True:\n",
    "    isTrue, frame = vid.read()\n",
    "    count += 1\n",
    "    if (count % 40 == 0):\n",
    "        blank = np.zeros(frame.shape, dtype='uint8')\n",
    "        saliency = cv2.saliency.StaticSaliencyFineGrained_create()\n",
    "        (success, saliencyMap) = saliency.computeSaliency(frame)\n",
    "        saliencyMap = (saliencyMap * 255).astype(\"uint8\")\n",
    "        threshMap3 = cv2.merge((saliencyMap,saliencyMap,saliencyMap))\n",
    "        result = yolo3(threshMap3, frame, network, a1, a2)\n",
    "\n",
    "        cv2.imshow(\"Original\", frame)\n",
    "        cv2.imshow(\"Saliency\", saliencyMap)\n",
    "        cv2.imshow(\"Result\", result)\n",
    "        result_vid.write(result)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if ((key == ord(\"q\")) or (isTrue == False)):\n",
    "        break\n",
    "vid.release()\n",
    "result_vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"C:\\\\BioVision_ds\\\\Saliency\\\\mRNA57.jpg\")\n",
    "image2 = np.zeros(image.shape, dtype='uint8')\n",
    "gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "edged = cv2.Canny(image, 10, 250)\n",
    "(cnts, hier) = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cont = cv2.drawContours(image2, cnts, -1, (0,255,0), 3)\n",
    "idx = 0\n",
    "for c in cnts:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    if w>50 and h>50:\n",
    "        idx+=1\n",
    "        new_img=image[y:y+h,x:x+w]\n",
    "        cv2.rectangle(image, (x, y),\n",
    "                          (x + w, y + h),\n",
    "                          (255, 0, 0), 2)\n",
    "cv2.imwrite(\"im1.jpg\",image)\n",
    "cv2.imwrite(\"cont1.jpg\", cont)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cont_detect(image):\n",
    "    image2 = image.copy()\n",
    "    gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    edged = cv2.Canny(image, 10, 250)\n",
    "    (cnts, hier) = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    idx = 0\n",
    "    for c in cnts:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        if w>50 and h>50:\n",
    "            idx+=1\n",
    "            cv2.rectangle(image2, (x, y),\n",
    "                              (x + w, y + h),\n",
    "                              (255, 0, 0), 2)\n",
    "\n",
    "    return image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bounding_box(image, x, y, w, h):\n",
    "    new_img=image[y:y+h,x:x+w]\n",
    "    area = (x+w)*(y+h)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "vid = cv2.VideoCapture(r\"C:\\Users\\shush\\OneDrive\\Documents\\Projects\\OpenCVtut\\videoplayback.mp4\")\n",
    "frame_width = int(vid.get(3))\n",
    "frame_height = int(vid.get(4))  \n",
    "size = (frame_width, frame_height)\n",
    "saliency = None\n",
    "obj_dect = cv2.createBackgroundSubtractorKNN()\n",
    "result_vid = cv2.VideoWriter('result.avi', \n",
    "                         cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "                         10, size)\n",
    "count = 0\n",
    "isTrue, frame = vid.read()\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "prev_frame = None\n",
    "while True:\n",
    "    isTrue, frame = vid.read()\n",
    "    count += 1\n",
    "    if prev_frame is None:\n",
    "        gray1 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray1 = cv2.GaussianBlur(gray1, (21, 21), 0)\n",
    "        prev_frame = gray1\n",
    "    if (count % 10 == 0):\n",
    "        blank = np.zeros(frame.shape, dtype='uint8')\n",
    "        saliency = cv2.saliency.StaticSaliencyFineGrained_create()\n",
    "        (success, saliencyMap) = saliency.computeSaliency(frame)\n",
    "        saliencyMap = (saliencyMap * 255).astype(\"uint8\")\n",
    "        threshMap = cv2.threshold(saliencyMap.astype(\"uint8\"), 0, 255,\n",
    "\tcv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "        threshMap3 = cv2.merge((threshMap,threshMap,threshMap))\n",
    "        result = cont_detect(frame)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "        frameDelta = cv2.absdiff(prev_frame, gray)\n",
    "        thresh = cv2.threshold(frameDelta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        prev_frame = gray\n",
    "\n",
    "        cv2.imshow(\"Original\", frame)\n",
    "        cv2.imshow(\"Saliency\", saliencyMap)\n",
    "        cv2.imshow(\"Delta\", frameDelta)\n",
    "        cv2.imshow(\"Result\", result)\n",
    "        result_vid.write(result)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if ((key == ord(\"q\")) or (isTrue == False)):\n",
    "        break\n",
    "vid.release()\n",
    "result_vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af6f8b2e9ffb58c89046067ce7cb7185c7d6e620480e496198fe0c411c46f7c8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('project': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
